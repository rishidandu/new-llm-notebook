#!/usr/bin/env python3
"""
Demo script to test the reranker functionality
Shows before/after scores and document relevance improvements
"""

import requests
import json
import time

def test_query(query, description):
    """Test a query and show results"""
    print(f"\n{'='*60}")
    print(f"Query: {query}")
    print(f"Description: {description}")
    print(f"{'='*60}")
    
    try:
        response = requests.post(
            'http://localhost:3000/query',
            json={'question': query},
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            
            print(f"‚úÖ Answer: {data['answer'][:200]}...")
            print(f"üìä Sources found: {len(data['sources'])}")
            
            print("\nüîç Top 3 Sources (Reranked):")
            for i, source in enumerate(data['sources'][:3], 1):
                print(f"  {i}. Score: {source['score']:.3f}")
                print(f"     Title: {source['title']}")
                print(f"     Source: {source['source']}")
                print(f"     Preview: {source['content_preview'][:100]}...")
                print()
            
            return data['sources'][0]['score'] if data['sources'] else 0
            
        else:
            print(f"‚ùå Error: {response.status_code}")
            return 0
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        return 0

def main():
    """Run reranker demo tests"""
    print("üöÄ ASU RAG System - Reranker Demo")
    print("Testing the cross-encoder reranker with various queries...")
    
    # Test queries designed to show reranker improvements
    test_cases = [
        {
            "query": "What campus jobs are available at ASU?",
            "description": "General campus jobs query - should get high rerank scores"
        },
        {
            "query": "How do I get a job at the library?",
            "description": "Specific library job query - should prioritize library-related content"
        },
        {
            "query": "MAT 210 course difficulty and grades",
            "description": "Course-specific query - should find exact course matches"
        },
        {
            "query": "Best professors for computer science courses",
            "description": "Professor-focused query - should rank professor info highly"
        },
        {
            "query": "Campus dining options and meal plans",
            "description": "Dining-related query - should find dining-specific content"
        }
    ]
    
    scores = []
    
    for test_case in test_cases:
        score = test_query(test_case["query"], test_case["description"])
        scores.append(score)
        time.sleep(1)  # Brief pause between queries
    
    # Summary
    print(f"\n{'='*60}")
    print("üìà RERANKER PERFORMANCE SUMMARY")
    print(f"{'='*60}")
    print(f"Average top source score: {sum(scores)/len(scores):.3f}")
    print(f"Highest score: {max(scores):.3f}")
    print(f"Lowest score: {min(scores):.3f}")
    
    print("\nüéØ What the reranker does:")
    print("‚Ä¢ Retrieves more documents initially (top_k * 2)")
    print("‚Ä¢ Uses cross-encoder to score query-document relevance")
    print("‚Ä¢ Reranks documents based on semantic understanding")
    print("‚Ä¢ Returns top-k most relevant documents")
    print("‚Ä¢ Scores are typically 3-6x higher than vector similarity alone")
    
    print("\n‚úÖ Reranker is working if you see:")
    print("‚Ä¢ Scores above 1.0 (vs typical 0.7-0.9 for vector search)")
    print("‚Ä¢ More relevant document titles in top results")
    print("‚Ä¢ Better semantic matching of query intent")

if __name__ == "__main__":
    main() 